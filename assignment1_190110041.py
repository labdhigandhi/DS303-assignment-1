# -*- coding: utf-8 -*-
"""Copy of Welcome To Colaboratory

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ihuAJZrsc0UIGnCJsdmh1TorjdIwIxx2
"""

#Q1

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import datetime as dt
from scipy import stats
from scipy.stats import norm

pd.options.display.float_format = '{:.0f}'.format

#load the data
url = 'https://raw.githubusercontent.com/labdhigandhi/FlightDelays/main/FlightDelays.csv'
data = pd.read_csv(url)

#see the first five rows of data
print(data.head())

#numerical columns description
print(data[['CRS_DEP_TIME','CARRIER','DEP_TIME','TAIL_NUM','Flight Status']].describe())

data[['DISTANCE','DAY_WEEK','DAY_OF_MONTH','Weather']].plot.box()
data[['DEP_TIME']].plot.box()

#correlation matrix
corrmat = data.corr()
f, ax = plt.subplots(figsize=(12, 9))
sns.heatmap(corrmat, vmax=.8, square=True,annot=True);
plt.show()


data.loc[data['Flight Status'] == "ontime", 'Flight Status'] = 0
data.loc[data['Flight Status'] == "delayed", 'Flight Status'] = 1

data.loc[data['ORIGIN'] == "DCA", 'ORIGIN'] = 1
data.loc[data['ORIGIN'] == "IAD", 'ORIGIN'] = 2
data.loc[data['ORIGIN'] == "BWI", 'ORIGIN'] = 3

data.loc[data['DEST'] == "JFK", 'DEST'] = 1
data.loc[data['DEST'] == "LGA", 'DEST'] = 2
data.loc[data['DEST'] == "EWR", 'DEST'] = 3

data.loc[data['CARRIER'] == "CO", 'CARRIER'] = 1
data.loc[data['CARRIER'] == "DH", 'CARRIER'] = 2
data.loc[data['CARRIER'] == "DL", 'CARRIER'] = 3
data.loc[data['CARRIER'] == "MQ", 'CARRIER'] = 4
data.loc[data['CARRIER'] == "OH", 'CARRIER'] = 5
data.loc[data['CARRIER'] == "RU", 'CARRIER'] = 6
data.loc[data['CARRIER'] == "UA", 'CARRIER'] = 7
data.loc[data['CARRIER'] == "US", 'CARRIER'] = 8

print(data.head())

f,ax=plt.subplots(1,2,figsize=(20,8))
data['Flight Status'].value_counts().plot.pie(explode=[0.05,0.05],autopct='%1.1f%%',ax=ax[0],shadow=True)
ax[0].set_title('Status')
ax[0].set_ylabel('')
sns.countplot('Flight Status',order = data['Flight Status'].value_counts().index, data=data,ax=ax[1])
ax[1].set_title('Status')
plt.show()

print('Status represents weather the flight was on time (0) or delayed (1) ')

f,ax=plt.subplots(1,2,figsize=(20,8))
data['ORIGIN'].value_counts().plot.pie(explode=[0.05,0.05,0.05],autopct='%1.1f%%',ax=ax[0],shadow=True)
ax[0].set_title('ORIGIN')
ax[0].set_ylabel('')
sns.countplot('ORIGIN',order = data['ORIGIN'].value_counts().index, data=data,ax=ax[1])
ax[1].set_title('ORIGIN')
plt.show()

print('Percentage of flights from various origins: DCA(1), IAD(2), BWI(3) ')

f,ax=plt.subplots(1,2,figsize=(20,8))
data['DEST'].value_counts().plot.pie(explode=[0.05,0.05,0.05],autopct='%1.1f%%',ax=ax[0],shadow=True)
ax[0].set_title('DEST')
ax[0].set_ylabel('')
sns.countplot('DEST',order = data['DEST'].value_counts().index, data=data,ax=ax[1])
ax[1].set_title('DEST')
plt.show()

print('Percentage of flights with various destinations: JFK(1), LGA(2), EWR(3) ')

f,ax=plt.subplots(1,2,figsize=(20,8))
data['CARRIER'].value_counts().plot.pie(explode=[0.05,0.05,0.05,0.05,0.05,0.05,0,0],autopct='%1.1f%%',ax=ax[0],shadow=True)
ax[0].set_title('CARRIER')
ax[0].set_ylabel('')
sns.countplot('CARRIER',order = data['CARRIER'].value_counts().index, data=data,ax=ax[1])
ax[1].set_title('CARRIER')
plt.show()

print('Percentage of flights with 8 different airline codes')

f,ax=plt.subplots(1,2,figsize=(20,8))
data['Weather'].value_counts().plot.pie(explode=[0.05,0.05],autopct='%1.1f%%',ax=ax[0],shadow=True)
ax[0].set_title('Weather Realated Delay')
ax[0].set_ylabel('')
sns.countplot('Weather',order = data['Weather'].value_counts().index, data=data,ax=ax[1])
ax[1].set_title('Flights with Weather Related Delay')
plt.show()

print('Percentage of flights with Weather related delay(1)')

#scatterplot
sns.set()
cols = ['CARRIER', 'DEP_TIME', 'DEST', 'DISTANCE', 'ORIGIN', 'DAY_WEEK', 'Weather', 'Flight Status']
sns.pairplot(data[cols], size = 2.5)
plt.show()

#Q2 and Q3

from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, roc_curve, roc_auc_score, precision_recall_curve, accuracy_score, f1_score

#load the data
url = 'https://raw.githubusercontent.com/labdhigandhi/FlightDelays/main/FlightDelays.csv'
data = pd.read_csv(url)
data.loc[data['Flight Status'] == "ontime", 'Flight Status'] = 0
data.loc[data['Flight Status'] == "delayed", 'Flight Status'] = 1

data.loc[data['ORIGIN'] == "DCA", 'ORIGIN'] = 1
data.loc[data['ORIGIN'] == "IAD", 'ORIGIN'] = 2
data.loc[data['ORIGIN'] == "BWI", 'ORIGIN'] = 3

data.loc[data['DEST'] == "JFK", 'DEST'] = 1
data.loc[data['DEST'] == "LGA", 'DEST'] = 2
data.loc[data['DEST'] == "EWR", 'DEST'] = 3

data.loc[data['CARRIER'] == "CO", 'CARRIER'] = 1
data.loc[data['CARRIER'] == "DH", 'CARRIER'] = 2
data.loc[data['CARRIER'] == "DL", 'CARRIER'] = 3
data.loc[data['CARRIER'] == "MQ", 'CARRIER'] = 4
data.loc[data['CARRIER'] == "OH", 'CARRIER'] = 5
data.loc[data['CARRIER'] == "RU", 'CARRIER'] = 6
data.loc[data['CARRIER'] == "UA", 'CARRIER'] = 7
data.loc[data['CARRIER'] == "US", 'CARRIER'] = 8


data = data.drop(["FL_DATE", "TAIL_NUM"], axis=1)
print("Sample entries in the dataset:")
print(data.head(50))

data['Flight Status'].value_counts()

def classwise_means(df):
    """Prints classwise averages for attributes present in the dataset (df)."""
    print('Classes in dataset: ')
    class_labels = df['Flight Status'].unique()
    print(class_labels)
    print('\n')
    print('Class-wise Attribute Averages')
    print(df.groupby(['Flight Status']).mean())

classwise_means(data)

sns.countplot(x='Flight Status', data=data)
plt.show()

#Train-Test split

# Following an 60-40 split on data.
# The dataset is shuffled with 99 as the random seed for reproducible results.
np_dataset = np.array(data)
X = np_dataset[:,:-1]
y = np_dataset[:,-1]
y=y.astype('int')
X_train,X_test,y_train,y_test = train_test_split(X,y,shuffle=True,test_size=0.40,random_state=99)
print("Shape of training dataset:",X_train.shape)
print("Shape of test dataset:",X_test.shape)
print("Number of train samples: ", len(X_train))
print("Number of test samples: ", len(X_test))

# Feature normalization
# Refer to https://scikit-learn.org/stable/modules/preprocessing.html#standardization-or-mean-removal-and-variance-scaling
scaler = StandardScaler()
scaler.fit(X_train)
X_train = scaler.transform(X_train)
X_test = scaler.transform(X_test)

# Fit model to training data
classifier = LogisticRegression(penalty='l2', tol=1e-6, max_iter=10000)
classifier.fit(X_train, y_train)

print('intercept:', classifier.intercept_)
print('coefficient:', classifier.coef_[0])
# Evaluate on test data 
y_pred = classifier.predict(X_test)

# Confusion Matrix
class_labels = data['Flight Status'].unique()
cm = confusion_matrix(y_test, y_pred, labels=class_labels)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_labels)
# switch off Seaborn theme for CM plot
sns.reset_orig()
disp.plot()

# Performance Statistics
print(classification_report(y_test, y_pred))

#Evaluation on test data
#y_pred = ((X_test@w_old)>0.5).astype(int)
print("Accuracy:",accuracy_score(y_test,y_pred))
print("F1 score:",f1_score(y_test,y_pred))

# switch to default Seaborn theme
sns.set_theme()

def plot_curve(y1, x1, y2, x2, y_label,  x_label, y1_label, y2_label, title):
    """For plotting metrics of 2 models"""
    plt.figure()
    plt.plot(x1, y1, label=y1_label)
    if not (x2 is None or y2 is None or y2_label is None):
        plt.plot(x2, y2, label=y2_label, linestyle='--')
    plt.xlabel(x_label)
    plt.ylabel(y_label)
    plt.title(title)
    plt.legend(loc="lower right")
    plt.show()

# ROC curve

# get probabilities of test sample being labelled as positive (1) from the LR model.
lr_probs = classifier.predict_proba(X_test)[:, 1]

# get roc curve vectors for plotting
fpr, tpr, thresholds = roc_curve(y_test, lr_probs)

# Compare with baseline 'No Skill' model which returns prob = 0 for all samples
ns_probs = [0.] * len(lr_probs)
ns_fpr, ns_tpr, _ = roc_curve(y_test, ns_probs)

# Area under ROC curve
lr_auc_roc = roc_auc_score(y_test, lr_probs)

# plot AUC
plot_curve(y1=tpr,
           x1=fpr,
           y2=ns_tpr,
           x2=ns_fpr,
           y_label='True Positive Rate',
           x_label='False Positive Rate',
           y1_label='Logistic Regression (area = %0.2f)' % lr_auc_roc,
           y2_label='No Skill Model (area = %0.2f)' % 0.5,
           title='ROC Curve')

# PR Curve
lr_precision, lr_recall, _ = precision_recall_curve(y_test, lr_probs)

# plot PR curve
plot_curve(y1=lr_precision,
           x1=lr_recall,
           y2=None,
           x2=None,
           y_label='Precision',
           x_label='Recall',
           y1_label='Logistic Regression',
           y2_label=None,
           title='PR Curve')

#Q4 and Q5

from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, roc_curve, roc_auc_score, precision_recall_curve,accuracy_score,f1_score

#load the data
url = 'https://raw.githubusercontent.com/labdhigandhi/FlightDelays/main/FlightDelays.csv'
data = pd.read_csv(url)
data.loc[data['Flight Status'] == "ontime", 'Flight Status'] = 0
data.loc[data['Flight Status'] == "delayed", 'Flight Status'] = 1

data.loc[data['ORIGIN'] == "DCA", 'ORIGIN'] = 1
data.loc[data['ORIGIN'] == "IAD", 'ORIGIN'] = 2
data.loc[data['ORIGIN'] == "BWI", 'ORIGIN'] = 3

data.loc[data['DEST'] == "JFK", 'DEST'] = 1
data.loc[data['DEST'] == "LGA", 'DEST'] = 2
data.loc[data['DEST'] == "EWR", 'DEST'] = 3

data.loc[data['CARRIER'] == "CO", 'CARRIER'] = 1
data.loc[data['CARRIER'] == "DH", 'CARRIER'] = 2
data.loc[data['CARRIER'] == "DL", 'CARRIER'] = 3
data.loc[data['CARRIER'] == "MQ", 'CARRIER'] = 4
data.loc[data['CARRIER'] == "OH", 'CARRIER'] = 5
data.loc[data['CARRIER'] == "RU", 'CARRIER'] = 6
data.loc[data['CARRIER'] == "UA", 'CARRIER'] = 7
data.loc[data['CARRIER'] == "US", 'CARRIER'] = 8


data = data.drop(["FL_DATE", "TAIL_NUM","FL_NUM", "CARRIER", "DISTANCE", "ORIGIN", "DAY_WEEK", "DEST","DAY_OF_MONTH"], axis=1)
print("Sample entries in the dataset:")
print(data.head())

data['Flight Status'].value_counts()

def classwise_means(df):
    """Prints classwise averages for attributes present in the dataset (df)."""
    print('Classes in dataset: ')
    class_labels = df['Flight Status'].unique()
    print(class_labels)
    print('\n')
    print('Class-wise Attribute Averages')
    print(df.groupby(['Flight Status']).mean())

classwise_means(data)

sns.countplot(x='Flight Status', data=data)
plt.show()

#Train-Test split

# Following an 60-40 split on data.
# The dataset is shuffled with 99 as the random seed for reproducible results.
np_dataset = np.array(data)
X = np_dataset[:,:-1]
y = np_dataset[:,-1]
y=y.astype('int')
X_train,X_test,y_train,y_test = train_test_split(X,y,shuffle=True,test_size=0.20,random_state=99)
print("Shape of training dataset:",X_train.shape)
print("Shape of test dataset:",X_test.shape)
print("Number of train samples: ", len(X_train))
print("Number of test samples: ", len(X_test))

# Feature normalization
# Refer to https://scikit-learn.org/stable/modules/preprocessing.html#standardization-or-mean-removal-and-variance-scaling
scaler = StandardScaler()
scaler.fit(X_train)
X_train = scaler.transform(X_train)
X_test = scaler.transform(X_test)

# Fit model to training data
classifier = LogisticRegression(penalty='l2', tol=1e-6, max_iter=10000)
classifier.fit(X_train, y_train)

print('intercept:', classifier.intercept_)
print('coefficient:', classifier.coef_[0])
# Evaluate on test data 
y_pred = classifier.predict(X_test)

# Confusion Matrix
class_labels = data['Flight Status'].unique()
cm = confusion_matrix(y_test, y_pred, labels=class_labels)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_labels)
# switch off Seaborn theme for CM plot
sns.reset_orig()
disp.plot()

# Performance Statistics
print(classification_report(y_test, y_pred))

#Evaluation on test data
#y_pred = ((X_test@w_old)>0.5).astype(int)
print("Accuracy:",accuracy_score(y_test,y_pred))
print("F1 score:",f1_score(y_test,y_pred))

# switch to default Seaborn theme
sns.set_theme()

def plot_curve(y1, x1, y2, x2, y_label,  x_label, y1_label, y2_label, title):
    """For plotting metrics of 2 models"""
    plt.figure()
    plt.plot(x1, y1, label=y1_label)
    if not (x2 is None or y2 is None or y2_label is None):
        plt.plot(x2, y2, label=y2_label, linestyle='--')
    plt.xlabel(x_label)
    plt.ylabel(y_label)
    plt.title(title)
    plt.legend(loc="lower right")
    plt.show()

# ROC curve

# get probabilities of test sample being labelled as positive (1) from the LR model.
lr_probs = classifier.predict_proba(X_test)[:, 1]

# get roc curve vectors for plotting
fpr, tpr, thresholds = roc_curve(y_test, lr_probs)

# Compare with baseline 'No Skill' model which returns prob = 0 for all samples
ns_probs = [0.] * len(lr_probs)
ns_fpr, ns_tpr, _ = roc_curve(y_test, ns_probs)

# Area under ROC curve
lr_auc_roc = roc_auc_score(y_test, lr_probs)

# plot AUC
plot_curve(y1=tpr,
           x1=fpr,
           y2=ns_tpr,
           x2=ns_fpr,
           y_label='True Positive Rate',
           x_label='False Positive Rate',
           y1_label='Logistic Regression (area = %0.2f)' % lr_auc_roc,
           y2_label='No Skill Model (area = %0.2f)' % 0.5,
           title='ROC Curve')

# PR Curve
lr_precision, lr_recall, _ = precision_recall_curve(y_test, lr_probs)

# plot PR curve
plot_curve(y1=lr_precision,
           x1=lr_recall,
           y2=None,
           x2=None,
           y_label='Precision',
           x_label='Recall',
           y1_label='Logistic Regression',
           y2_label=None,
           title='PR Curve')

#Q6

#load the data
url = 'https://raw.githubusercontent.com/labdhigandhi/FlightDelays/main/FlightDelays.csv'
data = pd.read_csv(url)
data.loc[data['Flight Status'] == "ontime", 'Status'] = 0
data.loc[data['Flight Status'] == "delayed", 'Status'] = 1

data.loc[data['ORIGIN'] == "DCA", 'ORIGIN'] = 1
data.loc[data['ORIGIN'] == "IAD", 'ORIGIN'] = 2
data.loc[data['ORIGIN'] == "BWI", 'ORIGIN'] = 3

data.loc[data['DEST'] == "JFK", 'DEST'] = 1
data.loc[data['DEST'] == "LGA", 'DEST'] = 2
data.loc[data['DEST'] == "EWR", 'DEST'] = 3

data.loc[data['CARRIER'] == "CO", 'CARRIER'] = 1
data.loc[data['CARRIER'] == "DH", 'CARRIER'] = 2
data.loc[data['CARRIER'] == "DL", 'CARRIER'] = 3
data.loc[data['CARRIER'] == "MQ", 'CARRIER'] = 4
data.loc[data['CARRIER'] == "OH", 'CARRIER'] = 5
data.loc[data['CARRIER'] == "RU", 'CARRIER'] = 6
data.loc[data['CARRIER'] == "UA", 'CARRIER'] = 7
data.loc[data['CARRIER'] == "US", 'CARRIER'] = 8

data = data.drop(["TAIL_NUM","FL_NUM", "DISTANCE","Flight Status"], axis=1)
data = data.query('ORIGIN==1 & DEST==3 & Status==0')
data = data.drop(["ORIGIN","DEST", "Status"], axis=1)
print(data) 
print(data['DAY_OF_MONTH'].value_counts())
print(data['CARRIER'].value_counts())
print(data['Weather'].value_counts())

print("The ideal conditions for the highest chance of an ontime flight from DC to New York are: Date = 2/01/2004 and 9/01/2004 ; Carrier = 6 ; Weather = 0")